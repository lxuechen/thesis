\begin{table}[th]
\footnotesize
\setlength\tabcolsep{2.4pt}
\caption{
Full fine-tuning larger pretrained models  with text infilling performs best.
Results are dev set accuracies. 
Bold numbers are the best for each privacy level based on two-sample test.
$\epsilon$ estimates based on numerically composing tradeoff functions.
}
\centering
\begin{tabular}{l cccc cccc}
\toprule
\multirow{2}[2]{*}{Method} 
& \multicolumn{4}{c}{\text{$\epsilon=3$}}
& \multicolumn{4}{c}{\text{$\epsilon=8$}} \\
\cmidrule(lr){2-5}
\cmidrule(lr){6-9}
 & MNLI-(m/mm) & QQP & QNLI & SST-2
 & MNLI-(m/mm) & QQP & QNLI & SST-2 \\
\midrule
RGP {(base)} & - & - & - & - & 80.5/79.6 & 85.5 & 87.2 & 91.6 \\
RGP {(large)} & - & - & - & - & 86.1/86.0	& 86.7 & 90.0 & 93.0 \\
\midrule
full (base)              & 82.47/82.10 & 85.41 & 84.62 & 86.12 & 83.30/83.13 & 86.15 & 84.81 & 85.89 \\
full (large)             & 85.53/85.81 & \textbf{86.65} & 88.94 & 90.71 & 86.28/86.54 & \textbf{87.49} & 89.42 & 90.94 \\
full + infilling (base)  & 82.45/82.99 & 85.56 & 87.42 & 91.86 & 83.20/83.46 & 86.08 & 87.94 & 92.09 \\
full + infilling (large) & \textbf{86.43/86.46} & 86.43 & \textbf{90.76}  & \textbf{93.04} & \textbf{87.02/87.26} & 87.47 & \textbf{91.10} & \textbf{93.81} \\
\midrule \midrule
$\epsilon$ &2.75 &2.75 &2.57 &2.41 &7.15 &7.16 &6.87 &6.69\\
\bottomrule
\end{tabular}
\label{table:glue}
\end{table}

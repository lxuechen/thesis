\subsection*{Ethics Statement}
While the present paper studies private NLP, all experiments performed herein are based on public and well-studied datasets. 

To the best of our knowledge, this work is the first to demonstrate that DP NLP can achieve promising levels of performance across a wide range of tasks with limited data. 
Our experimental results suggest that DP learning has the potential to be used in industry settings to build high performing applications with small private datasets without making big sacrifices in privacy.

On the other hand, we acknowledge that successful private learning has the potential to motivate companies to more aggressively collect user data, which could result in long-term privacy harms~\citep{rogaway2015moral,solove2005taxonomy}.
In addition, other societal harms not captured by DP (e.g., representation bias) can arise with more machine learning models being trained on private data.



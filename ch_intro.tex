\chapter{Introduction}

The issue of privacy has gained considerable recent attention in the machine learning community as an increasing amount of user-generated data on the internet becomes a potential source for training powerful predictive models.
Privacy attacks against machine learning pipelines have demonstrated that models trained without formal guarantees can reveal membership information and reconstruct training data~\cite{shokri2017membership,carlini2021extracting}.
These vulnerabilities are not merely of academic interest---they have already led to concrete societal harms and an increasing public distrust towards machine learning applications.
For instance, a South Korean company developed a chatbot based on (private) user data that regurgitated sensitive information such as nicknames and home addresses in its responses which led to a public relations incident~\cite{sk-chatbot}.
In addition, privacy concerns impede the development of data-driven systems in specialized domains such as health care and law where the vast amount of quality data is considered sensitive or proprietary.
These concerns present a serious challenge in fully realizing the societal benefits of AI and machine learning as they gain rising attention with tightening legislation and growing discussions on policy and ethics. 

Differential Privacy~\cite[DP]{dwork2014algorithmic} is a formal privacy guarantee.
Intuitively, a randomized algorithm satisfies DP if it is difficult (in a probabilistic sense) to distinguish the two outputs of the algorithm obtained on any two input datasets that are similar.
This implies that DP algorithms are provably resistant to membership inference~\cite{yeom2018privacy,wasserman2010statistical} and data reconstruction attacks~\cite{pmlr-v162-guo22c,hayes2023bounding}.
Due to its attractive properties, DP has become the gold standard privacy definition for statistical analysis with private data, and DP algorithms have been deployed in high-stakes scenarios such as the 2020 US census~\cite{us-census}.

In contrast to the growing adoption of DP for private data analysis, DP has seen limited industry adoption for deep learning with private data.
This can be partially attributed to the fact that most previous approaches for training deep learning models with DP were computationally intensive and/or incurred substantial performance penalties on the resulting model.

\section{Overview of Results}

\newpage
\section*{Bibliographic Notes}

The dissertation is based on the following peer-reviewed works.
* indicates equal contribution.

\paragraph{Chapter 3:} 
Li, Xuechen, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. "Large Language Models Can Be Strong Differentially Private Learners." International Conference on Learning Representations (ICLR), 2022~\cite{li2022large}.

\paragraph{Chapter 4:}
He, Jiyan*, Xuechen Li*, Da Yu*, Huishuai Zhang, Janardhan Kulkarni, Yin Tat Lee, Arturs Backurs, Nenghai Yu, and Jiang Bian. "Exploring the Limits of Differentially Private Deep Learning With Group-Wise Clipping." International Conference on Learning Representations (ICLR), 2023~\cite{he2022exploring}.

\paragraph{Chapter 5:}
Li, Xuechen*, Daogao Liu*, Tatsunori B. Hashimoto, Huseyin A. Inan, Janardhan Kulkarni, Yin-Tat Lee, and Abhradeep Guha Thakurta. "When Does Differentially Private Learning Not Suffer in High Dimensions?." Advances in Neural Information Processing Systems (2022)~\cite{li2022does}.

\newpage
\section*{Notation}
We use the following notation throughout.

\paragraph{Sets.} 
We reserve standard symbols for common sets.
Let $\mathbb{N}$ be the set of naturals (this includes 0), and $\mathbb{N}_+$ be the set of positive naturals (this excludes 0).
Let $\R$ be the set of reals.
For $n \in \mathbb{N}_+$, we define the shorthand $[n] = \{1, . . . , n\}$.
For a set $\mathcal{T}$, its size is represented by $|\mathcal{T}|$.

\paragraph{Linear Algebra.}
Given $d \in \mathbb{N}_+$, 
let $\mathbf{S}^d$ denote the set of $d \times d$ symmetric matrices, and $\mathbf{S}^d_+ \subset \mathbf{S}^d$ the positive semidefinite subset. 
Given $M \in \mathbf{S}^d$, let $\lambda_1(M) \ge \lambda_2(M) \ge \cdots \ge \lambda_d(M)$ denote its eigenvalues in descending order.

We use standard notation for various vector norms.
Let $v\in \R^d$ be a real vector with $d$ elements. 
We denote the Euclidean norm ($\ell^2$-norm) by $\|v\|_2$, 
the $\ell^\infty$-norm by $\|v\|_\infty$, and the $\ell^1$-norm by $\|v\|_1$.
Given $A \in \mathbf{S}^d_+$, let $\| x \|_A = (x^\top A x)^{1/2}$ denote the induced Mahalanobis norm.

\paragraph{Probability \& Statistics.}
We denote distributions using calligraphic letters, e.g., $\mathcal{D}, \mathcal{P}, \mathcal{Q}$. We use $x \sim \mathcal{D}$ to denote sampling an element $x$ from the distribution $\mathcal{D}$. For a random variable $X$ and event $O$, we denote the probability of the event as $\operatorname{Pr}[X\in O]$, the expectation of $X$ as $\mathbb{E}[X]$ and the variance as $\V[X]$. We denote the normal distribution with mean $\mu$ and standard deviation $\sigma$ as $\mathcal{N}\left(\mu, \sigma^2\right)$.

\paragraph{Miscellaneous.}
For scalar functions $f,g: \mathcal{X} \to \R$, we say $f \lesssim g$ if $f(x) \leq C g(x)$ for some numerical constant $C>0$ and all $x\in\mathcal{X}$. 

\chapter{Introduction}

The issue of privacy has gained considerable recent attention in the machine learning community as an increasing amount of user-generated data on the internet becomes a potential source for training powerful predictive models.
Privacy attacks against machine learning pipelines have demonstrated that models trained without formal guarantees can reveal membership information and reconstruct training data~\cite{shokri2017membership,carlini2021extracting}.
The demonstrated vulnerabilities are not merely of academic interest---they have already led to concrete societal harms and an increasing public distrust towards machine learning applications.
For instance, a South Korean company developed a chatbot based on (private) user data that regurgitated sensitive information such as nicknames and home addresses in its responses which led to a public relations incident~\cite{sk-chatbot}.
In addition, privacy concerns impede the development of data-driven systems in specialized domains such as health care and law where the vast amount of quality data is considered sensitive or proprietary.
These concerns present a serious challenge in fully realizing the societal benefits of AI and machine learning as they gain rising attention with tightening legislation and growing discussions on policy and ethics. 

\section{Overview of Results}

\newpage
\section*{Bibliographic Notes}

The dissertation is based on the following peer-reviewed works.
* indicates equal contribution.

\paragraph{Chapter 3:} 
Li, Xuechen, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. "Large Language Models Can Be Strong Differentially Private Learners." International Conference on Learning Representations (ICLR), 2022~\cite{li2021large}.

\paragraph{Chapter 4:}
He, Jiyan*, Xuechen Li*, Da Yu*, Huishuai Zhang, Janardhan Kulkarni, Yin Tat Lee, Arturs Backurs, Nenghai Yu, and Jiang Bian. "Exploring the Limits of Differentially Private Deep Learning With Group-Wise Clipping." International Conference on Learning Representations (ICLR), 2023~\cite{he2022exploring}.

\paragraph{Chapter 5:}
Li, Xuechen*, Daogao Liu*, Tatsunori B. Hashimoto, Huseyin A. Inan, Janardhan Kulkarni, Yin-Tat Lee, and Abhradeep Guha Thakurta. "When Does Differentially Private Learning Not Suffer in High Dimensions?." Advances in Neural Information Processing Systems (2022)~\cite{li2022does}.

\newpage
\section*{Notation}
We use the following notation throughout.

\paragraph{Sets.} 
We reserve standard symbols for common sets.
Let $\mathbb{N}$ be the set of naturals (this includes 0), and $\mathbb{N}_+$ be the set of positive naturals (this excludes 0).
Let $\R$ be the set of reals.
For $n \in \mathbb{N}_+$, we define the shorthand $[n] = \{1, . . . , n\}$.
For a set $\mathcal{T}$, its size is represented by $|\mathcal{T}|$.

\paragraph{Linear Algebra.}
Given $d \in \mathbb{N}_+$, 
let $\mathbf{S}^d$ denote the set of $d \times d$ symmetric matrices, and $\mathbf{S}^d_+ \subset \mathbf{S}^d$ the positive semidefinite subset. 
Given $M \in \mathbf{S}^d$, let $\lambda_1(M) \ge \lambda_2(M) \ge \cdots \ge \lambda_d(M)$ denote its eigenvalues in descending order.

We use standard notation for various vector norms.
Let $v\in \R^d$ be a real vector with $d$ elements. 
We denote the Euclidean norm ($\ell^2$-norm) by $\|v\|_2$, 
the $\ell^\infty$-norm by $\|v\|_\infty$, and the $\ell^1$-norm by $\|v\|_1$.
Given $A \in \mathbf{S}^d_+$, let $\| x \|_A = (x^\top A x)^{1/2}$ denote the induced Mahalanobis norm.

\paragraph{Probability \& Statistics.}
We denote distributions using calligraphic letters, e.g., $\mathcal{D}, \mathcal{P}, \mathcal{Q}$. We use $x \sim \mathcal{D}$ to denote sampling an element $x$ from the distribution $\mathcal{D}$. For a random variable $X$ and event $O$, we denote the probability of the event as $\operatorname{Pr}[X\in O]$, the expectation of $X$ as $\mathbb{E}[X]$ and the variance as $\V[X]$. We denote the normal distribution with mean $\mu$ and standard deviation $\sigma$ as $\mathcal{N}\left(\mu, \sigma^2\right)$.

\paragraph{Miscellaneous.}
For scalar functions $f, g$, we say $f \lesssim g$ if $f \leq C g$ for some numerical constant $C>0$. 
